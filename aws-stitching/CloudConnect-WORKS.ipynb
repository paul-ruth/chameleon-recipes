{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Internet2 CloudConnect with AWS Direct Connect using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note:**    AWS Direct Connect functionality requires a more hands-on approach and some manual steps. Assistance from the Chameleon team is likely required, especially if you do not have access to Internet2's CloudConnect portal. Please reach out if you're interested in working on a setup like this.\n",
    "\n",
    "</div>\n",
    "\n",
    "## Background\n",
    "\n",
    "Network configuration is a critical element of any experiment spanning research and commercial clouds. The most common option is to assign domain specific public Internet addresses to all nodes and send traffic over the traditional Internet.  This approach is adequate for many experiment but suffers from security and performance limitations. Another option is to use a virtual private network (VPN) as a tunnel between distributed sites; the VPN protects the architecture from common security attacks and allows remote cloud resources to be assigned local IP addresses and managed as if they were on-site. Both of these options have the advantage of easy implementation, but are limited by the performance of the public Internet, an important consideration for many experiments. \n",
    "\n",
    "Many computer science experiments require increased control of the wide area network, include everything from garunteed quality of service to low-level network programability using software defined networking.  Chameleon provides these capabilities though direct low-level network connection between the research and public clouds, however creating them is challenging. While most public clouds provide low-level networking services (e.g. [AWS Direct Connect](https://aws.amazon.com/directconnect/), [Azure ExpressRoute](https://azure.microsoft.com/en-us/services/expressroute/), or [Google Dedicated Interconnect](https://cloud.google.com/network-connectivity/docs/interconnect/concepts/dedicated-overview)), using them is typically expensive; on the research cloud side, they can involve complicated campus network configuration arrangements that often limit access to this type of experimental configuration to a few a few select scientists or campus IT staff themselves. \n",
    "\n",
    "Since 2016, the Chameleon testbed has provided direct connect using Internet2’s [Advanced Layer 2 service (AL2S)](https://www.internet2.edu/products-services/advanced-networking/layer-2-services/) via [ExoGENI](http://www.exogeni.net/). More recently, Internet2 has deployed its [CloudConnect](https://www.internet2.edu/products-services/advanced-networking/networking-for-cloud/) service that enables members to connect end points, such as those used for Chameleon direct AL2S connections, to AWS Direct Connect, Azure ExpressRoute, and Google Dedicated Interconnect sites. Thus, to create an experimental topology between Chameleon and commercial cloud the first step is to create a direct connection between Chameleon and a public cloud accessible using Internet2’s CloudConnect. Additionally, since public cloud direct connections configure routing between the cloud and external facility using BGP, a user also needs to deploy a BGP router on their resources. \n",
    "\n",
    "This Jupyter notebook walks through the deployment of an experiment spanning Chameleon and AWS using CloudConnect.  It deploys the network, compute servers, and a fully configured BGP router. Further, the BGP router can, optionally, be deployed on a dedicated OpenFlow networking switch or as software Quagga router existing on a standard x86 compute host.  The full networking configuration is depicted in the figure below.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"./CloudConnect-Figs/ChameleonCloudConnectSW.png\"><br>\n",
    "    <em>Experiment spanning Chameleon and AWS using Internet2 CloudConnect</em>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "The configuration of the experiment can be seen in the figure.  A BGP router was deployed on a Chameleon host connected\n",
    "to two dedicated 10 Gbps tenant networks. One was an externally connected network that was stitched to an Internet2 CloudConnect BGP router. The other was an internal network connected to other compute nodes on Chameleon. On the AWS side, the CloudConnect BGP router was connected to a Virtual Private Gateway (VPG). The router in a Virtual Private Cloud (VPC) was configured with default routes to a private\n",
    "Internet Gateway and custom routes through the dedicated Internet2 circuit to the isolated tenant network on Chameleon. The three BGP  routers cooperate to advertise routes between user-controlled subnets hosted on Chameleon and AWS. The infrastructure’s configuration is described in the Chameleon tutorial on using Internet2 CloudConnect.\n",
    "\n",
    "## Tutorial\n",
    "\n",
    "There are three components of the deployed infrastructure: Chameleon, AWS, and CloudConnect. Each step is described in the following sections. The configuration parameteres using in the example are shown in the following figure.\n",
    "\n",
    "<br>\n",
    "<center>\n",
    "    <img src=\"./CloudConnect-Figs/AWS-Config.png\"><br>\n",
    "    <em>Configuration Parameters</em>\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "#### Set the configuration variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project name and targeted region\n",
    "export OS_PROJECT_NAME='CH-816532'\n",
    "export OS_REGION_NAME='CHI@UC'\n",
    "\n",
    "# Any key you have uploaded to Chameleon\n",
    "export KEY_NAME='my_chameleon_key'\n",
    "\n",
    "# Location of the matching private key in your Jupyter container\n",
    "export PRIVATE_KEY_LOCATION=\"/home/${USER}/work/my_chameleon_key\"\n",
    "\n",
    "# Set a preface to be used to identify named experiment objects in Chameleon\n",
    "# You username is a good PREFACE.\n",
    "export PREFACE=${USER}\n",
    "\n",
    "# AWS VPC Network\n",
    "# Your Chameleon subnet that you want to connect that you want to route through the new link\n",
    "export VPC_SUBNET=\"192.168.1.0/24\" ##export REMOTE_SUBNET=\"192.168.1.0/24\"\n",
    "\n",
    "# AWS-to-Internet2 Network\n",
    "export AWS_SUBNET=\"192.168.2.0/24\"\n",
    "\n",
    "# Chameleon-to-Internet2 Network (i.e. \"External Network\")\n",
    "export EXTERNAL_SUBNET=\"192.168.3.0/24\" #export EXTERNAL_NET_CIDR=\"192.168.3.0/24\"\n",
    "export EXTERNAL_NET_INTERNET_GATEWAY_IP=\"192.168.3.254\"\n",
    "\n",
    "# Chameleon Internal Network\n",
    "export INTERNAL_SUBNET=\"192.168.4.0/24\" #INTERNAL_NET_CIDR=\"192.168.4.0/24\"\n",
    "export INTERNAL_SUBNET_ESC=\"192.168.4.0\\/24\"  #export LOCAL_SUBNET=\"192.168.4.0\\/24\"\n",
    "export INTERNAL_NET_INTERNET_GATEWAY_IP=\"192.168.4.254\"\n",
    "export INTERNAL_NET_DHCP_ALLOCATION_START=\"192.168.4.100\"\n",
    "export INTERNAL_NET_DHCP_ALLOCATION_END=\"192.168.4.200\"\n",
    "\n",
    "# AWS BGP Router\n",
    "export AWS_ASN=\"65001\"\n",
    "export AWS_ROUTER_EXTERNAL_IP=\"192.168.2.1\"\n",
    "export AWS_BGP_PASSWORD=\"AWSBgpAuthPass\"\n",
    "\n",
    "# Internet2 BGP Router\n",
    "export INTERNET2_ASN=\"55038\"\n",
    "export INTERNET2_ROUTER_IP_FACING_AWS=\"192.168.2.2\"\n",
    "export INTERNET2_ROUTER_IP_FACING_CHAMELEON=\"192.168.3.2\"\n",
    "\n",
    "# Chameleon BGP Router\n",
    "export CHAMELEON_ASN=\"65002\"\n",
    "export CHAMELEON_ROUTER_IP_FACING_INTERNET2=\"192.168.3.1\"\n",
    "export CHAMELEON_ROUTER_IP_FACING_INTERNAL=\"192.168.4.1\"\n",
    "export CHAMELEON_BGP_PASSWORD=\"ChameleonBgpAuthPass\"\n",
    "\n",
    "\n",
    "# AWS Configuration\n",
    "# To get your keys see: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html\n",
    "# The following assumes the .csv aquired from AWS is placed in your notebook's ~/work folder but hardcoding \n",
    "# the values here will also work.\n",
    "AWS_ACCESS_KEY_ID=`tail -n +2  ~/work/new_user_credentials.csv | cut -d, -f3`\n",
    "AWS_SECRRET_ACCESS_KEY=`tail -n +2  ~/work/new_user_credentials.csv | cut -d, -f4`\n",
    "\n",
    "DEFAULT_REGION_NAME='us-east-2'\n",
    "DEFAULT_OUTPUT_FORMAT='json'\n",
    "\n",
    "#Name of EXISTING VPC in your AWS account\n",
    "VPC_NAME=\"Chameleon_Direct_Connect_VPC\"\n",
    "\n",
    "#Desired name of the direct connect circuit\n",
    "DIRECT_CONNECT_NAME=\"Chameleon_Direct_Connect\"\n",
    "\n",
    "# AWS Connection (0-4096)\n",
    "AWS_VLAN=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chameleon Configuration\n",
    "\n",
    "First, we show how the create the Chameleon resources.\n",
    "\n",
    "#### Create Chameleon networks\n",
    "\n",
    "On Chameleon there are two separate networks. The external network connects to Internet2 while the internal network connects local Chameleon nodes. Later we will creata a BGP router that will route network traffic between these networks.\n",
    "\n",
    "##### Create the external network\n",
    "\n",
    "The external network must be able to stitch to an external exogeni stitchport. This is achomplished by reserving an externally stitchable isolated network and setting the provider network to exogeni. We will be managing our own router for this network and do not need Chameleon to create one for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the names of the lease and network\n",
    "EXTERNAL_NET_LEASE_NAME=\"${PREFACE}-AWS-Network-External-Lease\"\n",
    "EXTERNAL_NET_NAME=\"${PREFACE}-AWS-Network-External-Network\"\n",
    "\n",
    "#Set the provider network \n",
    "PROVIDER=\"exogeni\"\n",
    "\n",
    "blazar lease-create \\\n",
    "   --reservation resource_type=network,network_name=${EXTERNAL_NET_NAME},resource_properties=\"[\\\"==\\\",\\\"\\$physical_network\\\",\\\"$PROVIDER\\\"]\" \\\n",
    "   ${EXTERNAL_NET_LEASE_NAME}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTERNAL_SUBNET_NAME=\"${PREFACE}-AWS-Network-External-Subnet\"\n",
    " \n",
    "openstack subnet create --subnet-range ${EXTERNAL_SUBNET} \\\n",
    "                   --no-dhcp \\\n",
    "                   --gateway ${EXTERNAL_NET_INTERNET_GATEWAY_IP} \\\n",
    "                   --network ${EXTERNAL_NET_NAME} ${EXTERNAL_SUBNET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create the internal network\n",
    "\n",
    "The internal network connects to local Chameleon nodes.  This is achomplished by reserving an isolated network and setting the provider network to physnet1. The subnet and router for the internal network will be used by the nodes to access the public Internet.\n",
    "\n",
    "The internal network can, optionally, be an OpenFlow network or even a stichable network. The example below uses a standared isolated VLAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the names of the lease and network\n",
    "INTERNAL_NET_LEASE_NAME=\"${USER}-AWS-Network-Internal-Lease\"\n",
    "INTERNAL_NET_NAME=\"${USER}-AWS-Network-Internal-Name\"\n",
    "\n",
    "#Set the provider network \n",
    "PROVIDER=\"physnet1\"\n",
    "    \n",
    "blazar lease-create \\\n",
    "   --reservation resource_type=network,network_name=${INTERNAL_NET_NAME},resource_properties=\"[\\\"==\\\",\\\"\\$physical_network\\\",\\\"$PROVIDER\\\"]\" \\\n",
    "   ${INTERNAL_NET_LEASE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INTERNAL_NET_SUBNET_NAME=\"${PREFACE}-AWS-Network-Internal-Subnet\"\n",
    "INTERNAL_NET_ROUTER_NAME=\"${PREFACE}-AWS-Network-Internal-Router\"\n",
    "                   \n",
    "openstack subnet create --subnet-range ${INTERNAL_SUBNET} \\\n",
    "                   --dhcp \\\n",
    "                   --allocation-pool start=${INTERNAL_NET_DHCP_ALLOCATION_START},end=${INTERNAL_NET_DHCP_ALLOCATION_END} \\\n",
    "                   --gateway ${INTERNAL_NET_INTERNET_GATEWAY_IP} \\\n",
    "                   --network ${INTERNAL_NET_NAME} \\\n",
    "                   ${INTERNAL_NET_SUBNET_NAME}\n",
    "                   \n",
    "# Set the name of the public network for Internet access\n",
    "PUBLIC_NET=\"public\"\n",
    "\n",
    "openstack router create ${INTERNAL_NET_ROUTER_NAME}\n",
    "openstack router add subnet ${INTERNAL_NET_ROUTER_NAME} ${INTERNAL_NET_SUBNET_NAME} \n",
    "openstack router set --external-gateway ${PUBLIC_NET} ${INTERNAL_NET_ROUTER_NAME}\n",
    "\n",
    "# Set an external subnet that will be routed to the local BGP gateway instead of the default gateway.\n",
    "# This subnet must include the subnet used on AWS.\n",
    "openstack subnet set --host-route destination=${VPC_SUBNET},gateway=${CHAMELEON_ROUTER_IP_FACING_INTERNAL} ${INTERNAL_NET_SUBNET_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a lease for floating IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOATING_IP_LEASE_NAME=\"${USER}-AWS-BGP-FloatingIP\"\n",
    "\n",
    "AMOUNT=\"1\"\n",
    "\n",
    "PUBLIC_NETWORK_ID=$(openstack network show public -f value -c id)\n",
    "\n",
    "blazar lease-create \\\n",
    "  --reservation \"resource_type=virtual:floatingip,network_id=${PUBLIC_NETWORK_ID},amount=${AMOUNT}\" \\\n",
    "  \"$FLOATING_IP_LEASE_NAME\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the BGP router \n",
    "In this setup, 2 instances are created. \n",
    "\tBGP speaker (sw-bgp) is an instance that is built on a dual-nic Haswell node.\n",
    "Regular node (sw-instance-1) in the subnet can be built on a Skylake or Haswell node.\n",
    "\n",
    "Create a lease with 2-3 dual-nic Haswell nodes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lease for the BGP router.\n",
    "# Requires 1 Haswell Node with dual-NICs enabled\n",
    "#\n",
    "BGP_ROUTER_LEASE_NAME=\"${USER}-AWS-BGP-Router-Lease\" \n",
    "\n",
    "NODE_TYPE=\"compute_haswell\"\n",
    "MIN=1\n",
    "MAX=1\n",
    "\n",
    "blazar lease-create \\\n",
    "      --physical-reservation min=${MIN},max=${MAX},resource_properties=\"[\\\"and\\\",[\\\"==\\\",\\\"\\$network_adapters.1.enabled\\\",\\\"True\\\"],[\\\"==\\\",\\\"\\$node_type\\\",\\\"compute_haswell\\\"]]\" \\\n",
    "      ${BGP_ROUTER_LEASE_NAME}\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reservation ID\n",
    "BGP_ROUTER_RESERVATION_ID=$(blazar lease-show  -f json ${BGP_ROUTER_LEASE_NAME} | jq -r .reservations | jq -r .id)\n",
    "BGP_ROUTER_LEASE_ID=$(blazar lease-show  -f json ${BGP_ROUTER_LEASE_NAME} | jq -r .id)\n",
    "\n",
    "# Get network UUIDs\n",
    "NET_UUID_INTERNAL=$( openstack network show -f value -c id ${INTERNAL_NET_NAME} )\n",
    "NET_UUID_EXTERNAL=$( openstack network show -f value -c id ${EXTERNAL_NET_NAME} )\n",
    "\n",
    "BGP_ROUTER_NAME=\"${USER}-AWS-BGP-Router\" \n",
    "\n",
    "FLAVOR=\"baremetal\"\n",
    "IMAGE=\"CC-CentOS7\"\n",
    "\n",
    "openstack server create \\\n",
    "  --image ${IMAGE} \\\n",
    "  --flavor ${FLAVOR} \\\n",
    "  --key-name ${KEY_NAME} \\\n",
    "  --nic net-id=${NET_UUID_INTERNAL},v4-fixed-ip=${CHAMELEON_ROUTER_IP_FACING_INTERNAL} \\\n",
    "  --nic net-id=${NET_UUID_EXTERNAL},v4-fixed-ip=${CHAMELEON_ROUTER_IP_FACING_INTERNET2} \\\n",
    "  --hint reservation=${BGP_ROUTER_RESERVATION_ID} \\\n",
    "  --hint query='[\"=\",\"$hypervisor_hostname\",\"$PHYSICAL\"]' \\\n",
    "  ${BGP_ROUTER_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Associate floating IPs with instances.\n",
    "\n",
    "You must wait for the node to start spawning before you can associate a floating IP. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BGP_ROUTER_FLOATING_IP=$(lease_list_floating_ips \"$FLOATING_IP_LEASE_NAME\" | sed -n 1p)\n",
    "\n",
    "openstack server add floating ip \"$BGP_ROUTER_NAME\" \"$BGP_ROUTER_FLOATING_IP\" \\\n",
    "  && echo \"Attached floating ip $BGP_ROUTER_FLOATING_IP!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure BGP Router\n",
    "\n",
    "The following script will configure the BGP router node and install a docker container that will communicate with the Internet2 CloudConnect BGP router.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "login_command=\"ssh -o \\\"StrictHostKeyChecking no\\\" -i $PRIVATE_KEY_LOCATION cc@$BGP_ROUTER_FLOATING_IP\"\n",
    "\n",
    "IF_INTERNAL_NET='eth0'\n",
    "IF_EXTERNAL_NET='eth1'\n",
    "\n",
    "CHAMELEON_ROUTER_IP_FACING_INTERNET2_CIDR='${CHAMELEON_ROUTER_IP_FACING_INTERNET2}\\/24'\n",
    "CHAMELEON_ROUTER_IP_FACING_INTERNAL_CIDR='${CHAMELEON_ROUTER_IP_FACING_INTERNAL}\\/24'\n",
    "\n",
    "eval \"$login_command bash << EOF\n",
    "\n",
    "echo Configure external iface\n",
    "sudo ip addr add ${CHAMELEON_ROUTER_IP_FACING_INTERNET2}/24 dev ${IF_EXTERNAL_NET}\n",
    "\n",
    "sudo ip link set ${IF_INTERNAL_NET} up\n",
    "sudo ip link set ${IF_INTERNAL_NET} mtu 9000\n",
    "sudo ip link set ${IF_INTERNAL_NET} txqueuelen 10000\n",
    "\n",
    "sudo ip link set ${IF_EXTERNAL_NET} up\n",
    "sudo ip link set ${IF_EXTERNAL_NET} mtu 9000\n",
    "sudo ip link set ${IF_EXTERNAL_NET} txqueuelen 10000\n",
    "\n",
    "sudo iptables -I FORWARD -i ${IF_EXTERNAL_NET} -o ${IF_INTERNAL_NET} -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT\n",
    "sudo iptables -I FORWARD -i ${IF_INTERNAL_NET} -o ${IF_EXTERNAL_NET} -m state --state NEW,ESTABLISHED,RELATED -j ACCEPT \n",
    "\n",
    "#Remove the external route because this is the router\n",
    "sudo ip route del ${AWS_SUBNET}\n",
    "\n",
    "sudo sh -c 'echo net.core.rmem_max = 67108864 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.core.wmem_max = 67108864  >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_rmem = 4096 87380 33554432 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_wmem = 4096 65536 33554432 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_congestion_control=htcp >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_mtu_probing=1 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.core.default_qdisc = fq >> /etc/sysctl.conf'\n",
    "\n",
    "sudo sysctl -p \n",
    "\n",
    "#\n",
    "# Create Quagga and CorsaCRA instance\n",
    "\n",
    "sudo yum update -y\n",
    "sudo yum install -y yum-utils device-mapper-persistent-data lvm2\n",
    "\n",
    "sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n",
    "sudo yum install -y docker-ce\n",
    "\n",
    "sudo systemctl enable docker\n",
    "sudo systemctl start docker\n",
    "sudo systemctl status docker\n",
    "\n",
    "yum install -y git\n",
    "mkdir ~/corsa_cra\n",
    "cd ~/corsa_cra/ \n",
    "git init \n",
    "git config core.sparsecheckout true \n",
    "echo corsa_cra/corsa_cra/* >> .git/info/sparse-checkout \n",
    "git remote add -f origin https://mcevik0@github.com/RENCI-NRIG/exogeni-recipes.git \n",
    "git pull origin master \n",
    "\n",
    "\n",
    "cd ~/corsa_cra/corsa_cra/corsa_cra/docker/\n",
    "\n",
    "# Modify corsa_cra/quagga/bgpd.conf\n",
    "\n",
    "sed -r -i \\\"s/<LOCAL_ASN>/${CHAMELEON_ASN}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<LOCAL_ROUTER_IP>/${CHAMELEON_ROUTER_IP_FACING_INTERNET2}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<LOCAL_SUBNET>/${INTERNAL_SUBNET_ESC}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<REMOTE_ROUTER_IP>/${INTERNET2_ROUTER_IP_FACING_CHAMELEON}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<REMOTE_ASN>/${INTERNET2_ASN}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<REMOTE_DESC>/AWS/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "sed -r -i \\\"s/<BGP_PASSWORD>/${CHAMELEON_BGP_PASSWORD}/g\\\" corsa_cra/quagga/bgpd.conf\n",
    "\n",
    "# Modify  corsa_cra/quagga/zebra.conf\n",
    "\n",
    "sed -r -i \\\"s/<INTERFACE_FACING_AWS>/${IF_EXTERNAL_NET}/g\\\" corsa_cra/quagga/zebra.conf\n",
    "sed -r -i \\\"s/<INTERFACE_FACING_LOCAL>/${IF_INTERNAL_NET}/g\\\" corsa_cra/quagga/zebra.conf\n",
    "sed -r -i \\\"s/<IP_ADDRESS_FACING_AWS>/${CHAMELEON_ROUTER_IP_FACING_INTERNET2_CIDR}/g\\\" corsa_cra/quagga/zebra.conf\n",
    "sed -r -i \\\"s/<IP_ADDRESS_FACING_LOCAL>/${CHAMELEON_ROUTER_IP_FACING_INTERNAL_CIDR}/g\\\" corsa_cra/quagga/zebra.conf\n",
    "\n",
    "cd ~/corsa_cra/corsa_cra/corsa_cra/docker/ \n",
    "sudo docker build -t cra_2 . \n",
    "sudo docker run --rm -dit --privileged --network host -p 6653:6653 --name=cra_2 cra_2 \n",
    "sudo docker image ls\n",
    "\n",
    "EOF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add local compute nodes\n",
    "\n",
    "At this point the internal network is \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_FLOATING_IP_LEASE_NAME=\"${USER}-Node-FloatingIP\"\n",
    "\n",
    "AMOUNT=\"1\"\n",
    "\n",
    "PUBLIC_NETWORK_ID=$(openstack network show public -f value -c id)\n",
    "\n",
    "blazar lease-create \\\n",
    "  --reservation \"resource_type=virtual:floatingip,network_id=${PUBLIC_NETWORK_ID},amount=${AMOUNT}\" \\\n",
    "  \"$NODES_FLOATING_IP_LEASE_NAME\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create servers on the new network\n",
    "\n",
    "You can now create Chameleon nodes on the internal network that will be able to communicate over the CloudConnect link that we will create later in this tutorial. Any nodes can be created on the internal network. The example creates a single x86 haswell node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Lease for the BGP router.\n",
    "# Requires 1 Haswell Node with dual-NICs enabled\n",
    "#\n",
    "NODES_LEASE_NAME=\"${USER}-AWS-Nodes-Lease\" \n",
    "\n",
    "NODE_TYPE=\"compute_haswell\"\n",
    "MIN=1\n",
    "MAX=1\n",
    "\n",
    "blazar lease-create \\\n",
    "      --physical-reservation min=${MIN},max=${MAX},resource_properties=\"[\\\"==\\\",\\\"\\$node_type\\\",\\\"compute_haswell\\\"]\" \\\n",
    "      ${NODES_LEASE_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reservation ID\n",
    "NODES_RESERVATION_ID=$(blazar lease-show  -f json ${NODES_LEASE_NAME} | jq -r .reservations | jq -r .id)\n",
    "NODES_LEASE_ID=$(blazar lease-show  -f json ${NODES_LEASE_NAME} | jq -r .id)\n",
    "\n",
    "# Get network UUIDs\n",
    "NET_UUID_INTERNAL=$( openstack network show -f value -c id ${INTERNAL_NET_NAME} )\n",
    "\n",
    "NODES_NAME=\"${USER}-Node\" \n",
    "\n",
    "FLAVOR=\"baremetal\"\n",
    "IMAGE=\"CC-CentOS7\"\n",
    "\n",
    "openstack server create \\\n",
    "  --image ${IMAGE} \\\n",
    "  --flavor ${FLAVOR} \\\n",
    "  --key-name ${KEY_NAME} \\\n",
    "  --nic net-id=${NET_UUID_INTERNAL} \\\n",
    "  --hint reservation=${NODES_RESERVATION_ID} \\\n",
    "  --hint query='[\"=\",\"$hypervisor_hostname\",\"$PHYSICAL\"]' \\\n",
    "  ${NODES_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NODE_FLOATING_IP=$(lease_list_floating_ips \"$NODES_FLOATING_IP_LEASE_NAME\" | sed -n 1p)\n",
    "\n",
    "openstack server add floating ip \"$NODES_NAME\" \"$NODE_FLOATING_IP\" \\\n",
    "  && echo \"Attached floating ip $NODE_FLOATING_IP!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is probably worth configuring the node with jumbo frames for better performance. The following shows the network tuning we used to get the most bandwidth. These tunning parameters are recommended by [ESnet](https://fasterdata.es.net/host-tuning/linux/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "login_command=\"ssh -o \\\"StrictHostKeyChecking no\\\" -i $PRIVATE_KEY_LOCATION cc@$NODE_FLOATING_IP\"\n",
    "\n",
    "eval \"$login_command bash << EOF\n",
    "\n",
    "sudo ip link set eth0 mtu 9000\n",
    "sudo ip link set eth0 txqueuelen 10000\n",
    "\n",
    "# allow testing with buffers up to 64MB \n",
    "\n",
    "sudo sh -c 'echo net.core.rmem_max = 67108864 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.core.wmem_max = 67108864  >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_rmem = 4096 87380 33554432 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_wmem = 4096 65536 33554432 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_congestion_control=htcp >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.ipv4.tcp_mtu_probing=1 >> /etc/sysctl.conf'\n",
    "sudo sh -c 'echo net.core.default_qdisc = fq >> /etc/sysctl.conf'\n",
    "\n",
    "sudo sysctl -p \n",
    "\n",
    "EOF\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet2 CloudConnect \n",
    "\n",
    "The Internet2 CloudConnect connection must be created by an authorized administrator. We would be happy to create this connection for you. Please create a Chameleon support ticket and cut/paste the output of the following cell. \n",
    "\n",
    "You will need to add your AWS account number and the desired bandwith.\n",
    "\n",
    "If you are an authorized CloudConnect user and would like to be able to create your own links, please create a support ticket and we can disscuss support your request.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTSTITCH_VLAN=`openstack network show -c provider:segmentation_id -f value ${EXTERNAL_NET_NAME}`\n",
    "\n",
    "echo Bandwidth: See: https://aws.amazon.com/directconnect/pricing/\n",
    "echo Connection Name: $DIRECT_CONNECT_NAME\n",
    "\n",
    "echo AWS Account ID: Your AWS Account Number\n",
    "echo AWS VLAN: $AWS_VLAN\n",
    "echo AWS ASN: $AWS_ASN\n",
    "echo AWS Router Extenal IP: $AWS_ROUTER_EXTERNAL_IP\n",
    "echo Internet2 IP Facing AWS: $INTERNET2_ROUTER_IP_FACING_AWS\n",
    "echo AWS Subnet: $AWS_SUBNET\n",
    "echo AWS BGP Key: $AWS_BGP_PASSWORD\n",
    "\n",
    "echo Chameleon network VLAN: $DIRECTSTITCH_VLAN\n",
    "echo Chameleon Router External IP: $CHAMELEON_ROUTER_IP_FACING_INTERNET2\n",
    "echo Internet2 IP Facing AWS: $INTERNET2_ROUTER_IP_FACING_CHAMELEON\n",
    "echo Chameleon Router External SUBNET: $EXTERNAL_SUBNET\n",
    "echo Chameleon ASN: $CHAMELEON_ASN\n",
    "echo Chameleon Router AuthPassword: $CHAMELEON_BGP_PASSWORD\n",
    "echo Chameleon Region: $OS_REGION_NAME\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up AWS Direct Connect Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sudo yum -y install awscli\n",
    "\n",
    "# Note: can be done internativly with 'aws configure'\n",
    "aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID\n",
    "aws configure set aws_secret_access_key $AWS_SECRRET_ACCESS_KEY\n",
    "aws configure set default.region $DEFAULT_REGION_NAME\n",
    "aws configure set default.output $DEFAULT_OUTPUT_FORMAT\n",
    "\n",
    "\n",
    "\n",
    "#Needs try/catch b/c some vpcs don't have Tags/Names\n",
    "VPC_ID=`aws --output json ec2 describe-vpcs | jq -r '.Vpcs[] | try if .Tags[].Key == \"Name\" and .Tags[].Value == \"'${VPC_NAME}'\" then .VpcId else \"\" end catch \"\"'`\n",
    "\n",
    "echo VPC_ID $VPC_ID\n",
    "\n",
    "#Create VPG\n",
    "VPC_GATEWAY_ID=`aws --output json ec2 create-vpn-gateway --type ipsec.1 --amazon-side-asn 65001 | jq -r '.VpnGateway.VpnGatewayId'`\n",
    "echo VPC_GATEWAY_ID $VPC_GATEWAY_ID\n",
    "                                        \n",
    "                                        \n",
    "\n",
    "#Attach VPG to VPC\n",
    "aws --output json ec2 attach-vpn-gateway --vpc-id $VPC_ID --vpn-gateway-id $VPC_GATEWAY_ID\n",
    "\n",
    "\n",
    "ROUTE_TABLE_ID=`aws --output json ec2 describe-route-tables | jq -r '.RouteTables[] |  try if .VpcId == \"'${VPC_ID}'\" then .RouteTableId else \"\" end catch \"\"'`\n",
    "echo ROUTE_TABLE_ID $ROUTE_TABLE_ID\n",
    "\n",
    "\n",
    "aws --output json ec2 enable-vgw-route-propagation --gateway-id $VPC_GATEWAY_ID \\\n",
    "                                                   --route-table-id $ROUTE_TABLE_ID\n",
    "\n",
    "#Get directconnect conneciton id\n",
    "DIRECT_CONNECT_ID=`aws --output json directconnect describe-connections | jq -r '.connections[] |  try if .connectionName == \"'${DIRECTCONNECT_NAME}'\" then .connectionId else \"\" end catch \"\"'`\n",
    "echo DIRECTCONNECT_ID $DIRECT_CONNECT_ID\n",
    "\n",
    "\n",
    "aws --output json directconnect confirm-connection --connection-id $DIRECT_CONNECT_ID\n",
    "\n",
    "DIRECT_CONNECT_STATE=\"\"\n",
    "\n",
    "while [ \"$DIRECT_CONNECT_STATE\" != \"available\" ]\n",
    "do \n",
    "    sleep 10\n",
    "    #Needs try/catch b/c some instnaces don't have Tags/Names\n",
    "    DIRECT_CONNECT_STATE=`aws --output json directconnect describe-connections | jq -r '.connections[] |  try if .connectionName == \"'${DIRECT_CONNECT_NAME}'\" then .connectionState else \"\" end catch \"\"'`\n",
    "    echo DIRECTCONNECT_STATE $DIRECT_CONNECT_STATE\n",
    "done\n",
    "\n",
    "#Create DirectConnectGateway\n",
    "DIRECT_CONNECT_GATEWAY_NAME=\"dcgw-\"${DIRECT_CONNECT_NAME} \n",
    "\n",
    "aws --output json directconnect create-direct-connect-gateway --direct-connect-gateway-name $DIRECT_CONNECT_GATEWAY_NAME --amazon-side-asn $AWS_ASN\n",
    "\n",
    "#Needs try/catch b/c some instnaces don't have Tags/Names\n",
    "DIRECT_CONNECT_GW_ID=`aws --output json directconnect describe-direct-connect-gateways | jq -r '.directConnectGateways[] |  try if .directConnectGatewayName == \"'${DIRECT_CONNECT_GATEWAY_NAME}'\" then .directConnectGatewayId else \"\" end catch \"\"'`\n",
    "echo DIRECTCONNECT_GW_ID $DIRECT_CONNECT_GW_ID\n",
    "\n",
    "#Create VirtualPrivateGateway\n",
    "VIRTUAL_INTERFACE_NAME=\"vif-\"${DIRECT_CONNECT_NAME} \n",
    "\n",
    "AWS_ROUTER_EXTERNAL_IP_CIDR=${AWS_ROUTER_EXTERNAL_IP}/24\n",
    "INTERNET2_ROUTER_IP_FACING_AWS_CIDR=${INTERNET2_ROUTER_IP_FACING_AWS}/24\n",
    "\n",
    "MTU=9001\n",
    "\n",
    "aws --output json directconnect create-private-virtual-interface \\\n",
    "                                          --connection-id $DIRECT_CONNECT_ID \\\n",
    "                                          --new-private-virtual-interface virtualInterfaceName=${VIRTUAL_INTERFACE_NAME},vlan=${AWS_VLAN},asn=${INTERNET2_ASN},authKey=${AWS_BGP_PASSWORD},mtu=${MTU},amazonAddress=${AWS_ROUTER_EXTERNAL_IP_CIDR},customerAddress=${INTERNET2_ROUTER_IP_FACING_AWS_CIDR},directConnectGatewayId=${DIRECT_CONNECT_GW_ID}\n",
    "                                          \n",
    "                                          \n",
    "\n",
    "#Associate VPGW with DirectConnect GW\n",
    "\n",
    "aws --output json  directconnect create-direct-connect-gateway-association --direct-connect-gateway-id $DIRECT_CONNECT_GW_ID \\\n",
    "                                                                           --virtual-gateway-id $VPC_GATEWAY_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE Everything"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
